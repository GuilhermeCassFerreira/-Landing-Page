{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-BJ1WMprs7h"
      },
      "source": [
        "# Exemplo de Regressão com RNA\n",
        "\n",
        "Este notebook demonstra o uso da implementação de Rede Neural Artificial (RNA) para um problema de regressão.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDuTcq1jrs7o"
      },
      "source": [
        "## 1. Importação das Bibliotecas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "OHYyM4eRrs7p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Configurações de visualização\n",
        "plt.style.use('ggplot')\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e11-QT1rs7v"
      },
      "source": [
        "## 2. Importação da RNA\n",
        "\n",
        "Para usar este notebook no Google Colab, você precisará carregar a implementação da RNA.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "A1nBBSDers7w",
        "outputId": "b13a45dc-f7a7-45b4-b7a3-80c508559409",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RNA-Implementation'...\n",
            "remote: Enumerating objects: 171, done.\u001b[K\n",
            "remote: Counting objects: 100% (171/171), done.\u001b[K\n",
            "remote: Compressing objects: 100% (116/116), done.\u001b[K\n",
            "remote: Total 171 (delta 60), reused 157 (delta 46), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (171/171), 1.29 MiB | 5.49 MiB/s, done.\n",
            "Resolving deltas: 100% (60/60), done.\n",
            "/content/RNA-Implementation/RNA-Implementation/RNA-Implementation/RNA-Implementation\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    !git clone https://github.com/pedromandelli/RNA-Implementation.git\n",
        "    %cd RNA-Implementation\n",
        "    sys.path.insert(0, os.path.abspath(os.getcwd()))\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    # Adicionar o diretório src ao PYTHONPATH se estiver executando localmente\n",
        "    module_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
        "    if module_path not in sys.path:\n",
        "        sys.path.insert(0, module_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wFvv7oI7rs7w",
        "outputId": "2cc692a2-0b44-414d-fd53-9cfcd4fc5d5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importação da NeuralNetwork bem-sucedida.\n"
          ]
        }
      ],
      "source": [
        "# Importar a implementação da RNA\n",
        "from src.rna import NeuralNetwork\n",
        "print(\"Importação da NeuralNetwork bem-sucedida.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i2sikmhrs7y"
      },
      "source": [
        "## 3. Carregamento e Exploração dos Dados\n",
        "\n",
        "Nesta seção, carregaremos um conjunto de dados para o problema de regressão e faremos uma exploração inicial.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "scrolled": true,
        "id": "CCsa7mgBrs7z",
        "outputId": "08c931d4-4167-4ad1-d2e9-0e7de30d836b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'src/datasets/processed.winequality-white.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-26-2202348633.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../../src/datasets/winequality-white.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'quality'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'src/datasets/processed.winequality-white.csv'"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "    data_path = 'src/datasets/winequality-white.csv'\n",
        "else:\n",
        "    data_path = '../../src/datasets/winequality-white.csv'\n",
        "\n",
        "df = pd.read_csv(data_path, sep=';')\n",
        "\n",
        "X = df.drop('quality', axis=1).values\n",
        "y = df['quality'].values.reshape(-1, 1)\n",
        "\n",
        "# Visualizar as primeiras linhas do conjunto de dados\n",
        "print(\"Primeiras 5 linhas do conjunto de dados:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_ZosRqyrs70"
      },
      "outputs": [],
      "source": [
        "# Estatísticas descritivas\n",
        "df.describe()\n",
        "df.corr()  # correlação entre atributos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfEJE9w9rs74"
      },
      "source": [
        "## 4. Pré-processamento dos Dados\n",
        "\n",
        "Nesta seção, realizaremos o pré-processamento necessário para preparar os dados para o treinamento da RNA.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McEsUfuCrs77"
      },
      "outputs": [],
      "source": [
        "# Dividir os dados em treino (60%), validação (20%) e teste (20%) - seguindo a orientação do professor\n",
        "\n",
        "# Primeiro, separar 20% dos dados para teste\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "# Depois, separar 25% dos dados restantes para validação (25% de 80% = 20% do total)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.25, random_state=42)\n",
        "\n",
        "print(f\"Tamanho do conjunto de treinamento: {X_train.shape}\")\n",
        "print(f\"Tamanho do conjunto de validação: {X_val.shape}\")\n",
        "print(f\"Tamanho do conjunto de teste: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVNHsuFCrs78"
      },
      "outputs": [],
      "source": [
        "# Normalizar os dados\n",
        "scaler_X = StandardScaler()\n",
        "X_train = scaler_X.fit_transform(X_train)\n",
        "X_val = scaler_X.transform(X_val)\n",
        "X_test = scaler_X.transform(X_test)\n",
        "\n",
        "scaler_y = StandardScaler()\n",
        "y_train = scaler_y.fit_transform(y_train)\n",
        "y_val = scaler_y.transform(y_val)\n",
        "y_test = scaler_y.transform(y_test)\n",
        "\n",
        "print(\"Média e desvio padrão após normalização:\")\n",
        "print(f\"X_train média: {X_train.mean()}, desvio padrão: {X_train.std()}\")\n",
        "print(f\"y_train média: {y_train.mean()}, desvio padrão: {y_train.std()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s94Bk-Sers79"
      },
      "source": [
        "## 5. Visualização dos Dados\n",
        "\n",
        "Vamos visualizar algumas características dos dados para entender melhor o problema.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "x1l8ABfkrs79"
      },
      "outputs": [],
      "source": [
        "# Visualizar a relação entre as features e o target\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "features = df.columns.drop('quality')  # ou df.columns[:-1]\n",
        "fig, axes = plt.subplots(3, 4, figsize=(20, 12))  # há 11 features, então 3x4\n",
        "\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, feature_name in enumerate(features):\n",
        "    axes[i].scatter(df[feature_name], df['quality'], alpha=0.5, s=5)\n",
        "    axes[i].set_xlabel(feature_name)\n",
        "    axes[i].set_ylabel('Quality')\n",
        "    axes[i].set_title(f'{feature_name} vs Quality')\n",
        "\n",
        "# Esconde qualquer subplot vazio\n",
        "for j in range(len(features), len(axes)):\n",
        "    axes[j].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWjEMjuRrs79"
      },
      "source": [
        "## 6. Criação e Treinamento do Modelo\n",
        "\n",
        "Nesta seção, criaremos e treinaremos o modelo de RNA para o problema de regressão.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "q-oECVLprs79"
      },
      "outputs": [],
      "source": [
        "# Criar o modelo\n",
        "model = NeuralNetwork(\n",
        "    layer_sizes=[X_train.shape[1], 64, 32, 16, 1],\n",
        "    activation_functions=[ 'relu', 'relu', 'relu', 'linear']\n",
        ")\n",
        "\n",
        "print(\"Arquitetura do modelo:\")\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0iECk7Mrs7-"
      },
      "outputs": [],
      "source": [
        "# Treinar o modelo\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10000,\n",
        "    batch_size=32,\n",
        "    learning_rate=0.001,\n",
        "    loss_function='mse',\n",
        "    optimizer='momentum',\n",
        "    verbose=True,\n",
        "    validation_data=(X_val, y_val)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ie1oVX3rs7-"
      },
      "source": [
        "## 7. Avaliação do Modelo\n",
        "\n",
        "Nesta seção, avaliaremos o desempenho do modelo treinado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4h0oLdSors7-"
      },
      "outputs": [],
      "source": [
        "# Fazer predições no conjunto de teste\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Reverter a normalização para avaliar o desempenho nas unidades originais\n",
        "y_pred_original = scaler_y.inverse_transform(y_pred)\n",
        "y_test_original = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "# Calcular métricas de desempenho\n",
        "mse = mean_squared_error(y_test_original, y_pred_original)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test_original, y_pred_original)\n",
        "\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1I_ifJsFrs8A"
      },
      "outputs": [],
      "source": [
        "# Comparar com uma baseline (média simples)\n",
        "baseline_pred = np.full_like(y_test_original, scaler_y.inverse_transform(np.mean(y_train).reshape(1, -1)))\n",
        "baseline_mse = mean_squared_error(y_test_original, baseline_pred)\n",
        "baseline_rmse = np.sqrt(baseline_mse)\n",
        "baseline_r2 = r2_score(y_test_original, baseline_pred)\n",
        "\n",
        "print(f\"Baseline MSE: {baseline_mse:.4f}\")\n",
        "print(f\"Baseline RMSE: {baseline_rmse:.4f}\")\n",
        "print(f\"Baseline R²: {baseline_r2:.4f}\")\n",
        "print(f\"Melhoria sobre a baseline: {(1 - mse/baseline_mse)*100:.2f}%\")\n",
        "\n",
        "# Verificar se atende ao requisito do enunciado (erro < 50%)\n",
        "erro_relativo = rmse / np.mean(np.abs(y_test_original))\n",
        "print(f\"Erro relativo: {erro_relativo:.4f} ({erro_relativo*100:.2f}%)\")\n",
        "print(f\"O modelo {'atende' if erro_relativo < 0.5 else 'não atende'} ao requisito de erro < 50%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDwbcustrs8A"
      },
      "source": [
        "## 8. Visualização dos Resultados\n",
        "\n",
        "Nesta seção, visualizaremos os resultados do treinamento e as predições do modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csCrgUgurs8A"
      },
      "outputs": [],
      "source": [
        "# Reverter a normalização\n",
        "y_pred_original = scaler_y.inverse_transform(y_pred)\n",
        "y_test_original = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "# Gráfico Predicted vs Actual\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(y_test_original, y_pred_original, alpha=0.5, color='salmon')\n",
        "plt.plot([y_test_original.min(), y_test_original.max()],\n",
        "         [y_test_original.min(), y_test_original.max()],\n",
        "         'r--')  # linha ideal\n",
        "plt.xlabel('Actual Quality')\n",
        "plt.ylabel('Predicted Quality')\n",
        "plt.title('Predicted vs Actual (Desnormalizado)')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3TAtDP4rs8B"
      },
      "outputs": [],
      "source": [
        "# Visualizar a distribuição dos erros\n",
        "errors = y_pred_original - y_test_original\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(errors, bins=50, alpha=0.75)\n",
        "plt.axvline(x=0, color='r', linestyle='--')\n",
        "plt.title('Error Distribution')\n",
        "plt.xlabel('Prediction Error')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_pred_original, errors, alpha=0.5)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.title('Residual Plot')\n",
        "plt.xlabel('Predicted Value')\n",
        "plt.ylabel('Residual')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpZjWzeOrs8C"
      },
      "source": [
        "## 9. Conclusão\n",
        "\n",
        "Neste notebook, demonstramos o uso da nossa implementação de RNA para um problema de regressão. O modelo foi capaz de aprender a relação entre as features e o target, apresentando um desempenho satisfatório conforme mostrado pelas métricas de avaliação.\n",
        "\n",
        "O erro do modelo é inferior a 50%, atendendo ao requisito especificado no enunciado do projeto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOasRR2drs8C"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}